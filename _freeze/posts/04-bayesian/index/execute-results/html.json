{
  "hash": "91285e80ee7155fd1920455e7182c1d4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Mini Project 4: Bayesian Analysis\"\nauthor: \"Taylor Lum\"\ndate: \"2025-04-28\"\n---\n\n\n\nUsing Bayesian analysis to investigate the probability that Nadal wins a point on his own serve against Novak Djokovic at the French Open.\n\n\n\n\n\n\n\n## Priors\n\nSince our unknown parameter is $p$, which is always between 0 and 1, I will use Beta as the prior distribution.\n\nFor the non-informative scenario 1, a reasonable prior for $p$ is $Uniform(0,1) = Beta(1,1)$ since it gives an equal probability to all values between 0 and 1, which reflects the lack of knowledge.\n\nGiven the information in scenario 2, we can find good parameters for the prior that fit the given constraints.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntarget_mean <- 46/66\n\nalphas <- seq(0.1, 60, length.out = 500)\nbetas <- (1-46/66)*alphas/(46/66)\n\nparam_df <- tibble(alphas, betas)\n\nparam_df <- param_df |> mutate(vars = \n                    (alphas*betas)/((alphas + betas)^2*(alphas + betas + 1)))\n\n\ntarget_var <- 0.05657^2\n\nparam_df <- param_df |> mutate(dist_to_target = abs(vars - target_var))\n\nparam_df |> filter(dist_to_target == min(dist_to_target))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  alphas betas    vars dist_to_target\n   <dbl> <dbl>   <dbl>          <dbl>\n1   45.4  19.7 0.00320     0.00000374\n```\n\n\n:::\n:::\n\n\n\n$Beta(45.36,19.72)$\n\nGiven the information in scenario 3, we can find good parameters for the prior that fit the given constraints.\n\nGenerate possible pairs of alpha and beta values that result an a mean of 0.75\n\nRecall that the mean of a Beta distribution is calculated using: $\\frac{\\alpha}{\\alpha + \\beta}$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalpha <- seq(0.001, 300, length.out = 1000)\nbeta <- 0.25*alpha/0.75\npossible_params <- tibble(alpha,beta)\n```\n:::\n\n\n\nGiven we are \"almost sure\" that Nadal wins no less than 70% of his points on serve against Djokovic, we want $P(p < 0.70)$ to be a small value, and I am going with 0.02\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npossible_params %>% \n  mutate(probs = pbeta(0.70, alpha, beta)) %>%\n  mutate(dist_to_target = abs(probs - 0.02)) %>%\n  filter(dist_to_target == min(dist_to_target))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  alpha  beta  probs dist_to_target\n  <dbl> <dbl>  <dbl>          <dbl>\n1  252.  83.9 0.0200      0.0000289\n```\n\n\n:::\n:::\n\n\n\n$Beta(251.65,83.88)$\n\n|          | Non-Informative Prior | Informative Prior 1 | Informative Prior 2 |\n|:--------:|:---------------------:|:-------------------:|:-------------------:|\n| $\\alpha$ |           1           |      45.35511       |      251.6518       |\n| $\\beta$  |           1           |      19.71961       |      83.88394       |\n|   Mean   |          0.5          |       0.69697       |        0.75         |\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n## Data\n\nFrom class, we know we can update the prior distribution based on our data. If $y_{obs}$ is the number of points won:\n\n$g(p|y_{obs}) = Beta(y_{obs} + \\alpha, n - y_{obs} + \\beta)$\n\n$y_{obs} = 56$\n\n$n = 84$\n\nThe mean is equal to $\\frac{\\alpha}{\\alpha + \\beta}$:\n\nCarry out the math...\n\n|   | Non-Informative Posterior | Informative Posterior 1 | Informative Posterior 2 |\n|:----------------:|:----------------:|:----------------:|:----------------:|\n| $\\alpha$ | 57 | 101.3551 | 95.03965 |\n| $\\beta$ | 29 | 47.71961 | 41.01322 |\n| Mean | 0.6627907 | 0.6798947 | 0.7333149 |\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n|   | Non-Informative Posterior | Informative Posterior 1 | Informative Posterior 2 |\n|:----------------:|:----------------:|:----------------:|:----------------:|\n| Prior Mean | 0.5 | 0.69697 | 0.75 |\n| Posterior Mean | 0.6627907 | 0.6798947 | 0.6985494 |\n\nAll of the posterior means are between their prior mean and our value from the data ($\\frac{56}{84} = 0.667$), which makes sense.\n\n**90% Credible Intervals**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# non informative\nc(qbeta(0.05, 57, 29),qbeta(0.95, 57, 29))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5772453 0.7440061\n```\n\n\n:::\n\n```{.r .cell-code}\n# informative 1\nc(qbeta(0.05, 101.3551, 47.71961), qbeta(0.95, 101.3551, 47.71961))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6158797 0.7411561\n```\n\n\n:::\n\n```{.r .cell-code}\n# informative 2\nc(qbeta(0.05, 307.6518, 111.8839), qbeta(0.95, 307.6518, 111.8839))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6972162 0.7681476\n```\n\n\n:::\n:::\n\n\n\n# Report\n\nIn this project our end goal is to try and find the \"true\" distribution for the probability that Nadal wins a point on his own serve against Novak Djokovic at the French Open. The probability distribution for winning points given he takes $n$ serves can be modeled using a Binomial distribution, with parameters $n$ and $p$ where $p$ is the probability of Nadal winning the point for a single serve.\n\nThe parameter $p$ is our unknown that we want to find the distribution for. Before using our data, we need a prior that we can update with said data. For this project we have priors for 3 different scenarios. But for all 3 scenarios, we can use a Beta distribution to model as we know the value of $p$ can only be between 0 and 1. We can look at each resulting distribution and evaluate which we think best models Nadal's performance, and these final distributions will be affected by the priors we choose.\n\nFor the non-informative prior, I used a $Beta(1,1)$, which is the same as a $Uniform(0,1)$. This gives an equal probability for all values of $p$ since we assume we \"know nothing\" about the distribution before collecting any data.\n\nFor the first informative prior we are given previous data where Nadal won 46/66 points on his serves against Djokovic, so we can treat this as the mean. There is also a standard error of 0.05657 on this estimate. We can use this information to find a prior that fits these constraints. We know that the mean of a Beta distribution is equal to $\\frac{\\alpha}{\\alpha + \\beta}$. If we set this equal to 46/66 we can solve for $\\alpha$ in terms of $\\beta$. We can then run through values of $\\alpha$ and calculate the corresponding $\\beta$ that keeps the mean at 46/66. Then select the $\\alpha$ $\\beta$ pair with the variance closest to $0.05657^2$. This gave a prior of $Beta(45.36, 19.72)$.\n\nFor the second informative prior we are given a value of 0.75 to work with, and we can treat this as the mean. From the second piece of information we know that $P(p < 0.70)$ is a small value, so I used 0.02. Then similar to how we did the first informative prior, calculate $P(p < 0.70)$ for combinations of $\\alpha$ and $\\beta$ and select the combination that has $P(p < 0.70)$ closest to 0.02. This gave a prior of $Beta(251.65, 83.88)$.\n\n## Comparing the Posteriors\n\nThe three posterior distributions are all different because we started with different priors (different $\\alpha$ and $\\beta$ values). In class we figured out how to update our distribution using our data:\n\n$g(p|y_{obs}) = Beta(y_{obs} + \\alpha, n - y_{obs} + \\beta)$\n\nSo we can see that although each prior is updated in the same way, the initial $\\alpha$ and $\\beta$ values will have a strong influence on the resulting posterior.\n\n### Choosing a Posterior\n\nBased on the three posteriors, I would choose the first informative one. Although the second informative prior has the lowest variance by a fair margin (see below), it is only based on the *claims* of the commentator. So yes the distribution has a small variance, but this smaller range of values that the 90% credible interval covers may be inaccurate. The first informative one's prior was based on real (?) data from previous matches between Nadal and Djokovic, and for this reason I would pick it over both of the other options. It reflects known past performance of Nadal versus Djokovic, and based on the real data we have, the interval seems more reasonable. This first informative scenario gives us data to use where p = 0.667, and this value is not even in the credible interval for the second informative scenario.\n\n### Posterior Variance\n\n$Variance = \\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)}$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariance <- function(alpha, beta) {\n  var = (alpha*beta)/((alpha + beta)^2*(alpha + beta + 1))\n  return (var)\n}\n# non-informative\nvariance(noninformative_alpha, noninformative_beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.002568956\n```\n\n\n:::\n\n```{.r .cell-code}\n# informative 1\nvariance(informative_alpha1, informative_beta1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.001450197\n```\n\n\n:::\n\n```{.r .cell-code}\n# informative 2\nvariance(informative_alpha2, informative_beta2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0004650358\n```\n\n\n:::\n:::\n\n\n\nThe variance for the second informative posterior is lower than the variance for the other two because its prior started with a much lower variance. From the first graph you can see that the curve for the second prior is much taller and narrower, indicating a low variance. This makes sense because we knew the peak had to be \"centered\" over 0.75 and have only 2% of the density below 0.70, which is not far from 0.75. So although the distribution was adjusted by the observed data, 0.667 is not too far from 0.75, so the distribution stayed narrow. Since the distribution started with a relatively high confidence in Nadal's performance, it remained high.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}